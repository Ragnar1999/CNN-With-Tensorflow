{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Importing libraries \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from   tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Reading the data\n",
    "df=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Neural Network Parameters\n",
    "### 28*28=784\n",
    "\n",
    "num_inputs=784\n",
    "num_classes=10\n",
    "dropout=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Tensorflow data inputs\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=[None,num_inputs])\n",
    "Y=tf.placeholder(tf.float32,shape=[None,num_classes])\n",
    "keep_prob=tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Neural Network training parameters\n",
    "\n",
    "batch_size=200\n",
    "num_steps=400\n",
    "learning_rate=1e-3\n",
    "display_step=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Creating Network Architechture\n",
    "\n",
    "def convolution_img(x,W,b,strides=1):\n",
    "    x=tf.nn.conv2d(x,W,strides=[1,strides,strides,1],padding=\"SAME\")\n",
    "    x=tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def max_pooling_layer(x,k=3):\n",
    "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding=\"SAME\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Model Architechture Weights\n",
    "\n",
    "\n",
    "W={\"w1\":tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "   \"w2\": tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "   \"w3\": tf.Variable(tf.random_normal([7*7*64,1024])),  ###Converting into Dense \n",
    "   \"w4\": tf.Variable(tf.random_normal([1024,num_classes]))} ###Final Class Probabilities\n",
    "\n",
    "b={\"b1\":tf.Variable(tf.random_normal([32])),\n",
    "   \"b2\":tf.Variable(tf.random_normal([64])),\n",
    "   \"b3\":tf.Variable(tf.random_normal([1024])),\n",
    "   \"b4\":tf.Variable(tf.random_normal([num_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Model Architechture\n",
    "\n",
    "\n",
    "def Model_Conv(x,W,b,dropout):\n",
    "    x=tf.reshape(x,shape=[-1,28,28,1])\n",
    "    \n",
    "    ##Convolving & Pooling\n",
    "    c1=convolution_img(x,W[\"w1\"],b[\"b1\"],strides=1)\n",
    "    c1=max_pooling_layer(c1,k=2)\n",
    "    \n",
    "    ##Convolving & Pooling\n",
    "    \n",
    "    c1=convolution_img(c1,W[\"w2\"],b[\"b2\"],strides=1)\n",
    "    c1=max_pooling_layer(c1,k=2)\n",
    "    \n",
    "    \n",
    "    ## Fully-Connected Layer\n",
    "    c1=tf.reshape(c1,[-1,W[\"w3\"].get_shape().as_list()[0]])\n",
    "    c1=tf.matmul(c1,W[\"w3\"])   ##     [-1,7*7*64]*[7*7*64,1024]\n",
    "    c1=tf.add(c1,b[\"b3\"])      ## [-1,1024]\n",
    "    c1=tf.nn.relu(c1)\n",
    "    \n",
    "    ##Dropout\n",
    "    c1=tf.nn.dropout(c1,dropout)\n",
    "    \n",
    "    ##Output\n",
    "    c1=tf.matmul(c1,W[\"w4\"])  ##  [-1,1024]*[1024,num_classes]\n",
    "    c1=tf.add(c1,b[\"b4\"])\n",
    "    \n",
    "    return c1                 ##  [-1,num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Cost function Optimization & Model Evaluation\n",
    "\n",
    "probs=Model_Conv(X,W,b,dropout=keep_prob)\n",
    "predicted=tf.nn.softmax(probs)\n",
    "\n",
    "optim=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "cost_fn=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=probs,labels=Y))\n",
    "training=optim.minimize(cost_fn)\n",
    "\n",
    "\n",
    "actual=tf.argmax(Y,1)               ##   [[1,10,20],\n",
    "                                          [5,7,30]]\n",
    "preds=tf.argmax(predicted,1)\n",
    "\n",
    "accuracy=tf.equal(actual,preds)\n",
    "accuracy=tf.cast(accuracy,tf.float32)\n",
    "accuracy=tf.reduce_mean(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 85155.2578, Training Accuracy= 0.150\n",
      "Step 20, Minibatch Loss= 10913.5088, Training Accuracy= 0.565\n",
      "Step 40, Minibatch Loss= 4518.1465, Training Accuracy= 0.725\n",
      "Step 60, Minibatch Loss= 5104.1011, Training Accuracy= 0.800\n",
      "Step 80, Minibatch Loss= 3100.2927, Training Accuracy= 0.840\n",
      "Step 100, Minibatch Loss= 3195.2039, Training Accuracy= 0.860\n",
      "Step 120, Minibatch Loss= 2244.9724, Training Accuracy= 0.870\n",
      "Step 140, Minibatch Loss= 897.0003, Training Accuracy= 0.915\n",
      "Step 160, Minibatch Loss= 779.9336, Training Accuracy= 0.925\n",
      "Step 180, Minibatch Loss= 1207.9463, Training Accuracy= 0.920\n",
      "Step 200, Minibatch Loss= 1199.2750, Training Accuracy= 0.930\n",
      "Step 220, Minibatch Loss= 902.1171, Training Accuracy= 0.930\n",
      "Step 240, Minibatch Loss= 742.9398, Training Accuracy= 0.940\n",
      "Step 260, Minibatch Loss= 1146.4990, Training Accuracy= 0.940\n",
      "Step 280, Minibatch Loss= 1335.1587, Training Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 1303.1082, Training Accuracy= 0.935\n",
      "Step 320, Minibatch Loss= 530.8497, Training Accuracy= 0.945\n",
      "Step 340, Minibatch Loss= 905.5151, Training Accuracy= 0.935\n",
      "Step 360, Minibatch Loss= 331.0255, Training Accuracy= 0.955\n",
      "Step 380, Minibatch Loss= 304.5190, Training Accuracy= 0.965\n",
      "Step 400, Minibatch Loss= 801.9939, Training Accuracy= 0.935\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.957031\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "###Staring the Model training Session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = df.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(training, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost_fn, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) +   \",   Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: df.test.images[:256],\n",
    "                                      Y: df.test.labels[:256],\n",
    "                                      keep_prob: 1.0}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
